cnn_convlstm_full
-----------------

out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh'))(inputs)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh'))(out)
out = TimeDistributed(AveragePooling2D())(out)

out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh')(out)
out = ConvLSTM2D(filters=64, kernel_size=5, activation='tanh')(out)

out = Conv2DTranspose(64, kernel_size=5, activation='tanh')(out)
out = Conv2DTranspose(64, kernel_size=5, activation='tanh')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(32, kernel_size=3, activation='tanh')(out)
out = Conv2DTranspose(1, kernel_size=3, activation='tanh')(out)


cnn_convlstm_full_deeper  
------------------------
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh'))(inputs)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh'))(out)
out = TimeDistributed(AveragePooling2D())(out)

out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh')(out)
out = ConvLSTM2D(filters=128, kernel_size=3, return_sequences=True, activation='tanh')(out)
out = ConvLSTM2D(filters=64, kernel_size=3, activation='tanh')(out)

out = Conv2DTranspose(64, kernel_size=3, activation='tanh')(out)
out = Conv2DTranspose(64, kernel_size=3, activation='tanh')(out)
out = Conv2DTranspose(64, kernel_size=3, activation='tanh')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(32, kernel_size=3, activation='tanh')(out)
out = Conv2DTranspose(1, kernel_size=3, activation='tanh')(out)


cnn_convlstm_long_1
------------------------
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)

out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=128, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=3, activation='tanh', padding='same')(out)

out = Conv2DTranspose(64, kernel_size=3, activation='tanh', padding='same')(out)
out = Conv2DTranspose(64, kernel_size=3, activation='tanh', padding='same')(out)
out = Conv2DTranspose(64, kernel_size=3, activation='tanh', padding='same')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(32, kernel_size=3, activation='tanh', padding='same')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(1, kernel_size=3, activation='tanh', padding='same')(out)


cnn_convlstm_long_2
------------------------
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)

out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', padding='same')(out)

out = Conv2DTranspose(50, kernel_size=3, activation='tanh', padding='same')(out)
out = Conv2DTranspose(50, kernel_size=3, activation='tanh', padding='same')(out)
out = Conv2DTranspose(25, kernel_size=3, activation='tanh', padding='same')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(10, kernel_size=3, activation='tanh', padding='same')(out)
out = UpSampling2D()(out)
out = Conv2DTranspose(1, kernel_size=3, activation='tanh', padding='same')(out)



cnn_convlstm_seq2seq_win11 and cnn_convlstm_seq2seq_win11_2
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_3   (3 layers for encoder-decoder)
------------------------

encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_4
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(40, kernel_size=3, activation='relu', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(80, kernel_size=3, activation='relu', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(80, kernel_size=3, activation='relu', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='relu', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(75, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_5
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='relu', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(75, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_6  (more filters)
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(100, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=64, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)

cnn_convlstm_seq2seq_win11_7  (same as win11_6, but with kernel_size=5 for convlstm)
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(100, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=64, kernel_size=5, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 64)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=5, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
out = TimeDistributed(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_cnn_relu
------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='relu', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)




cnn_convlstm_seq2seq_win17
------------------------

encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

latent_dim = window_size // 2 // 2  # accounting for average pooling operations
self.decoder_input_shape = (latent_dim, latent_dim, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])

# IMPORTANT: padding='valid' here
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_morefilters
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=64, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

latent_dim = window_size // 2 // 2  # accounting for average pooling operations
self.decoder_input_shape = (latent_dim, latent_dim, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=32, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_morefilters_2  ( 3 layers for encoder-decoder)
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(32, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(64, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=64, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

latent_dim = window_size // 2 // 2  # accounting for average pooling operations
self.decoder_input_shape = (latent_dim, latent_dim, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=64, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
out = ConvLSTM2D(filters=32, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_dilated
------------------------------------------------

encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh'))(encoder_inputs)
out = TimeDistributed(Conv2D(50, kernel_size=3, dilation_rate=2, activation='tanh'))(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, dilation_rate=4, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', padding='same',
	return_state=True)(out)

print(f"encoder out: {encoder_outputs}")

# decoder

latent_dim = window_size - 2 * 3  # accounting for encoder conv operations
self.decoder_input_shape = (latent_dim, latent_dim, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=25, kernel_size=3, return_sequences=True, activation='tanh')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_h2c2
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out, h1, c1 = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, return_state=True, activation='tanh', 
	padding='same')(out)
encoder_outputs, h2, c2 = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, h1, c1])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([out, h2, c2])

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)



cnn_convlstm_seq2seq_win11_h3c3
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out, h1, c1 = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, return_state=True, activation='tanh', 
	padding='same')(out)
out, h2, c2 = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, return_state=True, activation='tanh', 
	padding='same')(out)
encoder_outputs, h3, c3 = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([decoder_inputs, h1, c1])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([out, h2, c2])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([out, h3, c3])

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_dec_input
IMPORTANT: also change 
	def form_model_inputs(self, x):
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='tanh', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='tanh', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='tanh', 
	padding='same', return_state=True, return_sequences=True)(out)

# decoder

out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', 
	padding='same')([encoder_outputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='tanh', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=encoder_inputs, outputs=out)


cnn_convlstm_seq2seq_win11_relu and cnn_convlstm_seq2seq_win11_relu_2
------------------------------------------------

encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='relu', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='relu', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
  # TODO: this gets a 2400x1 (12x2x2x50) vector, maybe it's worth reducing the dimensions in lstm layers?
out = TimeDistributed(Dense(100, activation='relu'))(out)
out = TimeDistributed(Dense(50, activation='relu'))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)


cnn_convlstm_seq2seq_win11_relu_3 and cnn_convlstm_seq2seq_win11_relu_4
------------------------------------------------
encoder_inputs = Input(shape=(segment_size, window_size, window_size, 1))
		
out = TimeDistributed(Conv2D(25, kernel_size=3, activation='relu', padding='same'))(encoder_inputs)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)
out = TimeDistributed(AveragePooling2D())(out)
out = TimeDistributed(Conv2D(50, kernel_size=3, activation='relu', padding='same'))(out)

# encoder
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
encoder_outputs, state_h, state_c = ConvLSTM2D(filters=50, kernel_size=3, activation='relu', 
	padding='same', return_state=True)(out)

# decoder

# here (2, 2) is the latent dimension - not kernel size
self.decoder_input_shape = (2, 2, 50)
decoder_inputs = Input(shape=(segment_size,) + self.decoder_input_shape)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', 
	padding='same')([decoder_inputs, state_h, state_c])
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)
out = ConvLSTM2D(filters=50, kernel_size=3, return_sequences=True, activation='relu', padding='same')(out)

out = TimeDistributed(Flatten())(out)

num_output_features = 1
out = TimeDistributed(Dense(75, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.002)))(out)
out = TimeDistributed(Dense(num_output_features, activation='linear'))(out)

self.model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=out)